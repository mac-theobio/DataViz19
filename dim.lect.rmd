---
title: "high-dimensional examples"
---

```{r pkgs, message=FALSE}
library(factoextra)
library(pheatmap)
library(tidyverse)
```

## Data

We usually think of high-dimensional data as consisting of multiple _measures_ on a group of samples:

* Number of "reads" of different bacterial proteins from a set of soil samples
* Decathlon scores from different competitors
* Health measures from different children

## Types of measures

Many scientists traditionally think of high-dimensional data as having parallel, continuous measures:

* read matrices from soil samples

These may be complemented by a smaller number of “metadata” variables, which may be more diverse in type (count, categorical, etc.):

* environmental variables associated with soil samples

More and more datasets don't follow this:

* Canadian longitudinal study on aging has a huge number of variables per person with a wide mixture of types

## Duality

We study the rows (samples) using the columns (measures)

* What do the observed proteins tell us about the functional relationships between different soil samples?
* What does differential success in decathlon events tell us about the athletes?

But we can also do the opposite!

* What do measurements across soil samples tell us about the functional relationships between proteins?
* What does differential success of athletes tell us about the relationship between events?

- easiest: matrix of numeric values/Euclidean distances OK/MVN
- categorical
    - few values: can colour/split
	- many values: convert to dummy variables? (random forest viz?)
- non-Euclidean distances
    - e.g. species diversity

## Decathlon events

```{r events}
print(names(decathlon2))
```

## Decathlon frame

```{r decathlon}
dec_frame <- (decathlon2[1:10]
	%>% rename_all(sub, pattern="^X", replacement="Run_")
	%>% mutate_at(vars(contains('Run_')), funs(-.))
	%>% rename_all(sub, pattern="110m.", replacement="")
	%>% mutate_all(scale)
)
```

## Pairs plot

![Iris pairs plot (iris.R)](iris.Rout.png)
* Slow, and not very good for more than 5 or 6 variables
* Base R may be faster for quick viz

## Heatmap

```{r dec_heatmap}
dec_mat <- as.matrix(dec_frame)
heatmap(dec_mat)
```

## Heatmap again

```{r dec_t_heatmap}
heatmap(t(dec_mat))
```

## Correlation heatmap

```{r corr_heatmap}
pheatmap(cor(dec_mat), cell.width = 10, cell.height = 10)
```

Better for visualizing groups of  events

## Athelete correlations

```{r corr_athlete}
pheatmap(cor(t(dec_mat)), cell.width = 4, cell.height = 4)
```

Better for visualizing groups of  events

## PCA

A beautiful decomposition based on the idea that data points are points in a Euclidean space

* Need to think about scaling

We can think about the PCA as a decomposition (making observed points from idealized points)

* And relax it by requiring _non-negative_ combinations of _non-negative_ components (NMF)

Or we can think about it as minimizing distances:

* And relax it with non-Euclidean distances (PCoA)
* … or a rank-based approach (NMDS)

## PCA decomposition

View loadings:

```{r pca}
pca_ath <- prcomp(dec_mat, scale=TRUE)
fviz_screeplot(pca_ath)
```

## Individuals

```{r fviz_ind}
fviz_pca_ind(pca_ath)
```

## Components

```{r fviz_loadings}
fviz_pca_var(pca_ath)
```


--------------------

```{r fviz_altloadings}
fviz_pca_var(pca_ath, axes=c(2, 3))
```

## Biplot

View scores and loadings:

```{r fviz_biplot}
fviz_pca_biplot(pca_ath)
```

## Non-metric dimensional scaling

```{r nmds}
library(vegan)
mds <- metaMDS(dec_mat, distance="euclidean")
```

## Nmds plot

```{r nmds_plot}
plot(mds)
```

The biplot is hard (but we can help you if you want to do it)
